{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AZ5fbSaKkP2x"
   },
   "source": [
    "# Diplodatos Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6mQMDM9okP3D"
   },
   "source": [
    "We present this peace of code to create the baseline for the competition, and as an example of how to deal with these kind of problems. The main goals are that you:\n",
    "\n",
    "1. Learn\n",
    "1. Try different models and see which one fits the best the given data\n",
    "1. Get a higher score than the given one in the current baseline example\n",
    "1. Try to get the highest score in the class :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnBAv7GkkP3M"
   },
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "colab_type": "code",
    "id": "WvngwS9QkP30",
    "outputId": "674f378f-6102-45c7-f07e-0e8bfd3057cc"
   },
   "outputs": [],
   "source": [
    "# load the given labels\n",
    "breed = pd.read_csv('../data/breed_labels.csv')\n",
    "color = pd.read_csv('../data/color_labels.csv')\n",
    "state = pd.read_csv('../data/state_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QJbJLVQykP4V"
   },
   "source": [
    "Now we take a look at the labels, just to understand what these are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ElABiJM1kP4e",
    "outputId": "8c9f054f-489e-46be-98bb-3ef188ef454a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BreedID</th>\n",
       "      <th>Type</th>\n",
       "      <th>BreedName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Affenpinscher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Afghan Hound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Airedale Terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Akbash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Akita</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BreedID  Type         BreedName\n",
       "0        1     1     Affenpinscher\n",
       "1        2     1      Afghan Hound\n",
       "2        3     1  Airedale Terrier\n",
       "3        4     1            Akbash\n",
       "4        5     1             Akita"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sxUXAhLKkP43",
    "outputId": "0c72be0e-9882-4f94-d8cb-6e89967b65f0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ColorID</th>\n",
       "      <th>ColorName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Golden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Cream</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ColorID ColorName\n",
       "0        1     Black\n",
       "1        2     Brown\n",
       "2        3    Golden\n",
       "3        4    Yellow\n",
       "4        5     Cream"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6dL9h-wxkP5O",
    "outputId": "1da3258b-5154-4f8d-9e46-3a21d21c6a2a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StateID</th>\n",
       "      <th>StateName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41336</td>\n",
       "      <td>Johor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41325</td>\n",
       "      <td>Kedah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41367</td>\n",
       "      <td>Kelantan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41401</td>\n",
       "      <td>Kuala Lumpur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41415</td>\n",
       "      <td>Labuan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>41324</td>\n",
       "      <td>Melaka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41332</td>\n",
       "      <td>Negeri Sembilan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>41335</td>\n",
       "      <td>Pahang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>41330</td>\n",
       "      <td>Perak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>41380</td>\n",
       "      <td>Perlis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>41327</td>\n",
       "      <td>Pulau Pinang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>41345</td>\n",
       "      <td>Sabah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>41342</td>\n",
       "      <td>Sarawak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>41326</td>\n",
       "      <td>Selangor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>41361</td>\n",
       "      <td>Terengganu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    StateID        StateName\n",
       "0     41336            Johor\n",
       "1     41325            Kedah\n",
       "2     41367         Kelantan\n",
       "3     41401     Kuala Lumpur\n",
       "4     41415           Labuan\n",
       "5     41324           Melaka\n",
       "6     41332  Negeri Sembilan\n",
       "7     41335           Pahang\n",
       "8     41330            Perak\n",
       "9     41380           Perlis\n",
       "10    41327     Pulau Pinang\n",
       "11    41345            Sabah\n",
       "12    41342          Sarawak\n",
       "13    41326         Selangor\n",
       "14    41361       Terengganu"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9xdf5exLkP5l"
   },
   "source": [
    "And now we are ready to deal with the *original* dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vFce3aKFkP5u"
   },
   "outputs": [],
   "source": [
    "original_df = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mbry18OckP6I",
    "outputId": "3ada7410-584e-4df5-c038-67feb2d66ff9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Type', 'Age', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n",
       "       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n",
       "       'Sterilized', 'Health', 'Quantity', 'Fee', 'State', 'Description',\n",
       "       'AdoptionSpeed', 'PID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8QyV5JmCkP6e",
    "outputId": "d0b3a83a-d6bc-42b7-d1de-9b2199ea5d6a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Dewormed</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Fee</th>\n",
       "      <th>State</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "      <th>PID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "      <td>10582.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.454734</td>\n",
       "      <td>10.520412</td>\n",
       "      <td>265.469854</td>\n",
       "      <td>74.388868</td>\n",
       "      <td>1.779059</td>\n",
       "      <td>2.230675</td>\n",
       "      <td>3.236912</td>\n",
       "      <td>1.856738</td>\n",
       "      <td>1.860518</td>\n",
       "      <td>1.460971</td>\n",
       "      <td>1.729730</td>\n",
       "      <td>1.566528</td>\n",
       "      <td>1.912115</td>\n",
       "      <td>1.036666</td>\n",
       "      <td>1.584011</td>\n",
       "      <td>20.809960</td>\n",
       "      <td>41345.994613</td>\n",
       "      <td>2.518900</td>\n",
       "      <td>7477.025799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.497970</td>\n",
       "      <td>18.374027</td>\n",
       "      <td>60.121490</td>\n",
       "      <td>123.434010</td>\n",
       "      <td>0.684763</td>\n",
       "      <td>1.743985</td>\n",
       "      <td>2.748595</td>\n",
       "      <td>2.974465</td>\n",
       "      <td>0.547535</td>\n",
       "      <td>0.593843</td>\n",
       "      <td>0.670791</td>\n",
       "      <td>0.701482</td>\n",
       "      <td>0.564041</td>\n",
       "      <td>0.198228</td>\n",
       "      <td>1.488348</td>\n",
       "      <td>78.397243</td>\n",
       "      <td>32.409109</td>\n",
       "      <td>1.176018</td>\n",
       "      <td>4310.921553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41324.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41326.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3768.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41326.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7473.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41401.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11200.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>41415.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>14992.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Type           Age        Breed1        Breed2        Gender  \\\n",
       "count  10582.000000  10582.000000  10582.000000  10582.000000  10582.000000   \n",
       "mean       1.454734     10.520412    265.469854     74.388868      1.779059   \n",
       "std        0.497970     18.374027     60.121490    123.434010      0.684763   \n",
       "min        1.000000      0.000000      0.000000      0.000000      1.000000   \n",
       "25%        1.000000      2.000000    265.000000      0.000000      1.000000   \n",
       "50%        1.000000      3.000000    266.000000      0.000000      2.000000   \n",
       "75%        2.000000     12.000000    307.000000    188.000000      2.000000   \n",
       "max        2.000000    255.000000    307.000000    307.000000      3.000000   \n",
       "\n",
       "             Color1        Color2        Color3  MaturitySize     FurLength  \\\n",
       "count  10582.000000  10582.000000  10582.000000  10582.000000  10582.000000   \n",
       "mean       2.230675      3.236912      1.856738      1.860518      1.460971   \n",
       "std        1.743985      2.748595      2.974465      0.547535      0.593843   \n",
       "min        1.000000      0.000000      0.000000      1.000000      1.000000   \n",
       "25%        1.000000      0.000000      0.000000      2.000000      1.000000   \n",
       "50%        2.000000      2.000000      0.000000      2.000000      1.000000   \n",
       "75%        3.000000      6.000000      5.000000      2.000000      2.000000   \n",
       "max        7.000000      7.000000      7.000000      4.000000      3.000000   \n",
       "\n",
       "         Vaccinated      Dewormed    Sterilized        Health      Quantity  \\\n",
       "count  10582.000000  10582.000000  10582.000000  10582.000000  10582.000000   \n",
       "mean       1.729730      1.566528      1.912115      1.036666      1.584011   \n",
       "std        0.670791      0.701482      0.564041      0.198228      1.488348   \n",
       "min        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "25%        1.000000      1.000000      2.000000      1.000000      1.000000   \n",
       "50%        2.000000      1.000000      2.000000      1.000000      1.000000   \n",
       "75%        2.000000      2.000000      2.000000      1.000000      1.000000   \n",
       "max        3.000000      3.000000      3.000000      3.000000     20.000000   \n",
       "\n",
       "                Fee         State  AdoptionSpeed           PID  \n",
       "count  10582.000000  10582.000000   10582.000000  10582.000000  \n",
       "mean      20.809960  41345.994613       2.518900   7477.025799  \n",
       "std       78.397243     32.409109       1.176018   4310.921553  \n",
       "min        0.000000  41324.000000       0.000000      0.000000  \n",
       "25%        0.000000  41326.000000       2.000000   3768.250000  \n",
       "50%        0.000000  41326.000000       2.000000   7473.500000  \n",
       "75%        0.000000  41401.000000       4.000000  11200.750000  \n",
       "max     3000.000000  41415.000000       4.000000  14992.000000  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WOVVhrBxkP6z"
   },
   "source": [
    "Create a function to transform the datasets. This is done by means of a function so that the transformations are the same for the training and testing datasets... We replace the encodings just to make it easy to \"visualize\" the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DXKoGEJwkP66"
   },
   "outputs": [],
   "source": [
    "def transform_data(train_data_fname, test_data_fname):\n",
    "    def transform_columns(df):\n",
    "        df = df.drop([\"Description\"], axis=1)\n",
    "        df.Type = df.Type.replace({1: 'Dog', 2: 'Cat'})\n",
    "        df.Gender = df.Gender.replace({1:'Male', 2:'Female', 3:'Mixed'})\n",
    "        df.MaturitySize = df.MaturitySize.replace({1:'S', 2:'M', 3:'L', 4:'XL', 0:'N/A'})\n",
    "        df.FurLength = df.FurLength.replace({1:'S', 2:'M', 3:'L', 0:'N/A'})\n",
    "        df.Vaccinated = df.Vaccinated.replace({1:'T', 2:'N', 3:'N/A'})\n",
    "        df.Dewormed = df.Dewormed.replace({1:'T', 2:'F', 3:'N/A'})\n",
    "        df.Sterilized = df.Sterilized.replace({1:'T', 2:'F', 3:'N/A'})\n",
    "        df.Health = df.Health.replace({1:'Healthy', 2: 'MinorInjury', 3:'SeriousInjury', 0: 'N/A'})\n",
    "        df.Color1 = df.Color1.replace(dict(list(zip(color.ColorID, color.ColorName)) + [(0, \"N/A\")]))\n",
    "        df.Color2 = df.Color2.replace(dict(list(zip(color.ColorID, color.ColorName)) + [(0, \"N/A\")]))\n",
    "        df.Color3 = df.Color3.replace(dict(list(zip(color.ColorID, color.ColorName)) + [(0, \"N/A\")]))\n",
    "        df.Breed1 = df.Breed1.replace(dict(list(zip(breed.BreedID, breed.BreedName)) + [(0, \"N/A\")]))\n",
    "        df.Breed2 = df.Breed2.replace(dict(list(zip(breed.BreedID, breed.BreedName)) + [(0, \"N/A\")]))\n",
    "        return df\n",
    "    \n",
    "    df_train = pd.read_csv(train_data_fname)\n",
    "    df_train = transform_columns(df_train)\n",
    "    df_test = pd.read_csv(test_data_fname)\n",
    "    df_test = transform_columns(df_test)\n",
    "    \n",
    "    df = pd.concat([df_train, df_test], sort=True)\n",
    "\n",
    "    # set dummy variables for everything\n",
    "    # except from Age, Quantity, Fee\n",
    "    df = pd.get_dummies(df)\n",
    "    # get train and test back\n",
    "    n = len(df_train)\n",
    "    df_train = df.iloc[:n]\n",
    "    df_test = df.iloc[n:]\n",
    "    \n",
    "    y = df_train['AdoptionSpeed']\n",
    "    X = df_train.drop('AdoptionSpeed', axis=1)\n",
    "    yy = None\n",
    "    XX = df_test.drop('AdoptionSpeed', axis=1)\n",
    "\n",
    "    return X, y, XX, yy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KBHXxkykkP7U"
   },
   "source": [
    "Load the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rvKSlLRCkP7a"
   },
   "outputs": [],
   "source": [
    "X, y, XX, yy = transform_data(\"../data/train.csv\", \"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=('clf', 'best_acc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importar Grid Search y las métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Los hiperparámetros por omisión del sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30809717 0.30741191 0.31482982]\n",
      "0.31011296512160474\n"
     ]
    }
   ],
   "source": [
    "dt_basal = DecisionTreeClassifier(random_state=42)\n",
    "scores = cross_val_score(estimator=dt_basal, X=X_train.drop([\"PID\"], axis=1), y=y_train, cv=3)\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "#print(dt_basal)\n",
    "results = results.append({'clf': dt_basal, 'best_acc': scores.mean()}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probamos con GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probamos un Decision Tree agregando algunos hiperparámetros a los anteriores. Los hiperparámetros que evaluamos, con Grid Search, son:\n",
    "- criterio: gini y entropy\n",
    "- min_samples_leaf [1...7]\n",
    "- min_samples_split [2 ... 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VrtCr_8hkP7x",
    "outputId": "20fac039-d6e9-40cc-c3f4-ee689f7af2f5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree accuracy:  0.37234878199372645\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=7, min_samples_split=200,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best')\n",
      "The best classifier so far is: \n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=7, min_samples_split=200,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "tree_param = {\n",
    "    'criterion': ('gini', 'entropy'), \n",
    "    'min_samples_leaf': (1, 2, 5, 7),\n",
    "    'min_samples_split': (2, 3, 5, 10, 25, 50, 100, 200)\n",
    "}\n",
    "             \n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf = GridSearchCV(tree, tree_param, scoring='accuracy', cv=5, iid=False)\n",
    "tree_clf.fit(X_train.drop([\"PID\"], axis=1), y_train)\n",
    "best_tree_clf = tree_clf.best_estimator_\n",
    "#score general de accuracy\n",
    "print('Best Decision Tree accuracy: ', tree_clf.best_score_)\n",
    "print(best_tree_clf)\n",
    "results = results.append({'clf': best_tree_clf, 'best_acc': tree_clf.best_score_}, ignore_index=True)\n",
    "\n",
    "print('The best classifier so far is: ')\n",
    "print(results.loc[results['best_acc'].idxmax()]['clf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Los mejores hiperparámetros que selecciona grid search son:\n",
    "- criterio : entropy\n",
    "- min_samples_leaf : 7\n",
    "- min_samples_split : 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Luego probamos con más opciones para min_samples_leaf y min_samples_split, porque ambos daban los mejores hiperparámetros en el máximo del rango que probamos para ambos hiperparámetros (200 y 7, respectivamente). También agregamos class_weight para probar con \"balanceada\" además del None que es el valor por defecto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree accuracy:  0.374508938839338\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=12, min_samples_split=200,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best')\n",
      "The best classifier so far is: \n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=12, min_samples_split=200,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "tree_param = {'criterion':('entropy',), 'min_samples_leaf':(7,10, 12, 15),\n",
    "              'min_samples_split':(100,200, 300, 400), 'max_leaf_nodes':(None,),\n",
    "             'class_weight':('balanced',None) }\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf = GridSearchCV(tree, tree_param, scoring='accuracy', cv=5, iid=False)\n",
    "tree_clf.fit(X_train.drop([\"PID\"], axis=1), y_train)\n",
    "best_tree_clf = tree_clf.best_estimator_\n",
    "#score general de accuracy\n",
    "print('Best Decision Tree accuracy: ', tree_clf.best_score_)\n",
    "print(best_tree_clf)\n",
    "results = results.append({'clf': best_tree_clf, 'best_acc': tree_clf.best_score_}, ignore_index=True)\n",
    "\n",
    "print('The best classifier so far is: ')\n",
    "print(results.loc[results['best_acc'].idxmax()]['clf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### El min_samples_split óptimo sigue siendo 200. Para min_samples_leaf, el mejor hiperparámetro da 12 (en vez de 7 como en el caso anterior). Para class_weight, sigue optimizándose con igual peso todas las clases. Cambia mńimamente el accuracy respecto al anterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### importar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parámetros por defecto RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carla/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/carla/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33319838 0.32766302 0.30794165]\n",
      "0.3229343517311454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carla/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "rf_basal = RandomForestClassifier(random_state=42)\n",
    "\n",
    "scores = cross_val_score(estimator=rf_basal, X=X_train.drop([\"PID\"], axis=1), y=y_train, cv=3)\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "#print(dt_basal)\n",
    "results = results.append({'clf': rf_basal, 'best_acc': scores.mean()}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random search CV para el RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   25.0s\n",
      "/home/carla/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  5.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree accuracy:  0.3763989932178637\n",
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=60, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=2, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=780, n_jobs=None,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
      "The best classifier so far is: \n",
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=60, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=2, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=780, n_jobs=None,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "# nro de árboles\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 1000, num = 10)]\n",
    "# nro de features para agrupar\n",
    "max_features = ['auto', 'sqrt']\n",
    "# max nro de niveles del árbol\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# min nro de muestras para separar el nodo\n",
    "min_samples_split = [2, 10, 100, 400]\n",
    "# min nro de muestras por hoja\n",
    "min_samples_leaf = [1, 2, 7, 12, 15]\n",
    "# método para seleccionar las muestras\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "rf_random = RandomizedSearchCV(estimator = clf, param_distributions = random_grid, \n",
    "                               n_iter = 100, cv = 3, verbose=2, random_state=42, \n",
    "                               n_jobs = -1, scoring='accuracy', iid=False)\n",
    "#rf_clf = GridSearchCV(clf, rf_param, scoring='accuracy', cv=3, iid=False)\n",
    "rf_random.fit(X_train.drop([\"PID\"], axis=1), y_train)\n",
    "rf_random.best_params_\n",
    "best_rf_random_clf = rf_random.best_estimator_\n",
    "print('Best Decision Tree accuracy: ', rf_random.best_score_)\n",
    "print(best_rf_random_clf)\n",
    "results = results.append({'clf': best_rf_random_clf, 'best_acc': rf_random.best_score_}, ignore_index=True)\n",
    "\n",
    "print('The best classifier so far is: ')\n",
    "print(results.loc[results['best_acc'].idxmax()]['clf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carla/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/carla/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/carla/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/carla/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/carla/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "rf_rand_results = pd.DataFrame(rf_random.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
       "       'param_n_estimators', 'param_min_samples_split',\n",
       "       'param_min_samples_leaf', 'param_max_features', 'param_max_depth',\n",
       "       'param_bootstrap', 'params', 'split0_test_score', 'split1_test_score',\n",
       "       'split2_test_score', 'mean_test_score', 'std_test_score',\n",
       "       'rank_test_score', 'split0_train_score', 'split1_train_score',\n",
       "       'split2_train_score', 'mean_train_score', 'std_train_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_rand_results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 780, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 60, 'bootstrap': False} 0.3763989932178637\n",
      "{'n_estimators': 780, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 90, 'bootstrap': False} 0.3763989932178637\n",
      "{'n_estimators': 670, 'min_samples_split': 100, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 90, 'bootstrap': False} 0.3759965407061358\n",
      "{'n_estimators': 230, 'min_samples_split': 100, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 70, 'bootstrap': False} 0.37572592429761703\n",
      "{'n_estimators': 1000, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 50, 'bootstrap': False} 0.37477841160724995\n",
      "{'n_estimators': 340, 'min_samples_split': 100, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': None, 'bootstrap': False} 0.3742417722176749\n",
      "{'n_estimators': 890, 'min_samples_split': 100, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': None, 'bootstrap': True} 0.37410818632170684\n",
      "{'n_estimators': 120, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': False} 0.37356700856219255\n",
      "{'n_estimators': 1000, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': False} 0.37356432908129533\n",
      "{'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 60, 'bootstrap': True} 0.3732940951963251\n"
     ]
    }
   ],
   "source": [
    "rf_resultados = rf_rand_results.sort_values(['mean_test_score'], ascending=False)[['params', 'mean_test_score']][:10]\n",
    "for index, row in rf_resultados.iterrows():\n",
    "    print(row['params'], row['mean_test_score'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF con grid search con los hiperparámetros que nos dieron. Pero salvo min_samples_leaf, no se ven otros valores que se mantengan dentro de un rango acotado (qué significa eso? ... que dan más o menos lo mismo, entonces ninguno optimiza significativamente?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree accuracy:  0.37640189115709144\n",
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=90, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=100,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=None,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
      "The best classifier so far is: \n",
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=90, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=100,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=None,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "rf_param = {'n_estimators': (250, 500, 800), \n",
    "            'min_samples_leaf': (1,),\n",
    "            'min_samples_split': (2, 50, 100), \n",
    "            'max_features': ('sqrt', 'auto'), \n",
    "            'max_depth': (50, 90, None),\n",
    "            'bootstrap': (True, False)\n",
    "            }\n",
    "\n",
    "clf = RFT(random_state=42)\n",
    "rf_clf = GridSearchCV(clf, rf_param, scoring='accuracy', cv=3, iid=False)\n",
    "rf_clf.fit(X_train.drop([\"PID\"], axis=1), y_train)\n",
    "best_rf_clf = rf_clf.best_estimator_\n",
    "\n",
    "print('Best Decision Tree accuracy: ', rf_clf.best_score_)\n",
    "print(best_rf_clf)\n",
    "\n",
    "results = results.append({'clf': best_rf_clf, 'best_acc': rf_clf.best_score_}, ignore_index=True)\n",
    "\n",
    "print('The best classifier so far is: ')\n",
    "print(results.loc[results['best_acc'].idxmax()]['clf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Los mejores hiperparámetros que selecciona grid search para el random forest son:\n",
    "- criterio : gini\n",
    "- min_samples_leaf : 1\n",
    "- min_samples_split : 100\n",
    "\n",
    "Pero la mejora es prácticamente nula respecto al random search (0.376399 0.376402))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33481781 0.31065209 0.30267423]\n",
      "0.3160480432585906\n"
     ]
    }
   ],
   "source": [
    "knn_basal = KNeighborsClassifier()\n",
    "\n",
    "scores = cross_val_score(estimator=knn_basal, X=X_train.drop([\"PID\"], axis=1), y=y_train, cv=3)\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "#print(dt_basal)\n",
    "results = results.append({'clf': knn_basal, 'best_acc': scores.mean()}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hicimos un grid search sobre algunos de los hiperparámetros para el knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Knn accuracy:  0.341565706915526\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
      "           weights='distance')\n",
      "The best classifier so far is: \n",
      "The best classifier so far is: \n",
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=90, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=100,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=None,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "Knn_param = {\n",
    "    'n_neighbors': [3, 5, 10], \n",
    "    'weights': ['uniform', 'distance'], \n",
    "    'p': [1, 2] \n",
    "}\n",
    "\n",
    "knn_clf = GridSearchCV(KNeighborsClassifier(), Knn_param, scoring='accuracy', cv=3, iid=False)\n",
    "knn_clf.fit(X_train.drop([\"PID\"], axis=1), y_train)\n",
    "best_knn_clf = knn_clf.best_estimator_\n",
    "print('Best Knn accuracy: ', knn_clf.best_score_)\n",
    "print(best_grid_clf)\n",
    "results = results.append({'clf': best_knn_clf, 'best_acc': knn_clf.best_score_}, ignore_index=True)\n",
    "\n",
    "print('The best classifier so far is: ')\n",
    "print(results.loc[results['best_acc'].idxmax()]['clf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mejora respecto a los parámetros por omisión pero está bastante por debajo de decision tree y árboles de decisión - no seguimos probando con otros hiperparámetros para knn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carla/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/carla/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/carla/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/carla/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/carla/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/carla/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best sgd accuracy:  0.2729843880791654\n",
      "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
      "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_iter_no_change=5, n_jobs=None, penalty='l1', power_t=0.5,\n",
      "       random_state=42, shuffle=True, tol=0.1, validation_fraction=0.1,\n",
      "       verbose=0, warm_start=False)\n",
      "The best classifier so far is: \n",
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=90, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=100,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=None,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carla/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'alpha': (1,0.0001), \n",
    "    'average': (False, ), \n",
    "    'class_weight': (None, ), \n",
    "    'early_stopping': (False, ), \n",
    "    'eta0': (0.0, ), \n",
    "    'fit_intercept': (True, ), \n",
    "    'l1_ratio': (0.15, ), \n",
    "    'learning_rate': ('optimal', ),\n",
    "    'loss': ('hinge', 'modified_huber'), \n",
    "    'max_iter': (1000, ), \n",
    "    'n_iter': (None, ), \n",
    "    'n_iter_no_change': (5, ), \n",
    "    'n_jobs': (None, ), \n",
    "    'penalty': ('l1', 'l2',),  \n",
    "    'power_t': (0.5, ), \n",
    "    'random_state': (42, ), \n",
    "    'shuffle': (True, ), \n",
    "    'tol': (0.1, ), \n",
    "    'validation_fraction': (0.1, ),\n",
    "    'warm_start': (False, ),\n",
    "}\n",
    "\n",
    "clf_class = SGDClassifier\n",
    "\n",
    "sgd_clf = GridSearchCV(clf_class(), params, scoring='accuracy', cv=3, iid=False)\n",
    "sgd_clf.fit(X_train.drop([\"PID\"], axis=1), y_train)\n",
    "best_sgd_clf = sgd_clf.best_estimator_\n",
    "\n",
    "print('Best sgd accuracy: ', sgd_clf.best_score_)\n",
    "print(best_sgd_clf)\n",
    "results = results.append({'clf': best_sgd_clf, 'best_acc': sgd_clf.best_score_}, ignore_index=True)\n",
    "\n",
    "print('The best classifier so far is: ')\n",
    "print(results.loc[results['best_acc'].idxmax()]['clf'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluamos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best') 0.31011296512160474\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=100,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best') 0.3519622095560508\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=7, min_samples_split=200,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best') 0.37234878199372645\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=12, min_samples_split=200,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best') 0.374508938839338\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False) 0.3229343517311454\n",
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=60, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=2, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=780, n_jobs=None,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False) 0.3763989932178637\n",
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=90, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=100,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=None,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False) 0.37640189115709144\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform') 0.3160480432585906\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
      "           weights='distance') 0.341565706915526\n",
      "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
      "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_iter_no_change=5, n_jobs=None, penalty='l1', power_t=0.5,\n",
      "       random_state=42, shuffle=True, tol=0.1, validation_fraction=0.1,\n",
      "       verbose=0, warm_start=False) 0.2729843880791654\n"
     ]
    }
   ],
   "source": [
    "for index, val in results.iterrows():\n",
    "    print (val['clf'],val['best_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculamos sobre el conjunto de entrenamiento completo con los modelos e hiperparámetros que seleccionamos, y usamos ese modelo en validación. Calcular el accuracy y comparar los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best') 0.31011296512160474\n",
      "1.0 0.2992125984251969 0.31011296512160474\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=100,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best') 0.3519622095560508\n",
      "0.47144592952612396 0.33858267716535434 0.3519622095560508\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=7, min_samples_split=200,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best') 0.37234878199372645\n",
      "0.4132577291751046 0.36787401574803147 0.37234878199372645\n",
      "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=12, min_samples_split=200,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=42,\n",
      "            splitter='best') 0.374508938839338\n",
      "0.4155528554070474 0.3625196850393701 0.374508938839338\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False) 0.3229343517311454\n",
      "0.9828540569731335 0.3366929133858268 0.3229343517311454\n",
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=60, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=2, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=780, n_jobs=None,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False) 0.3763989932178637\n",
      "0.8504117726474956 0.38677165354330706 0.3763989932178637\n",
      "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=90, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=100,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=None,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False) 0.37640189115709144\n",
      "0.5677062238423113 0.38173228346456695 0.37640189115709144\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform') 0.3160480432585906\n",
      "0.48521668691778047 0.24535433070866142 0.3160480432585906\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
      "           weights='distance') 0.341565706915526\n",
      "1.0 0.2620472440944882 0.341565706915526\n",
      "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
      "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_iter_no_change=5, n_jobs=None, penalty='l1', power_t=0.5,\n",
      "       random_state=42, shuffle=True, tol=0.1, validation_fraction=0.1,\n",
      "       verbose=0, warm_start=False) 0.2729843880791654\n",
      "0.277845281490482 0.288503937007874 0.2729843880791654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carla/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "for index, val in results.iterrows():\n",
    "    print (val['clf'],val['best_acc'])\n",
    "    clf = val['clf']\n",
    "    clf_t = clf.fit(X_train, y_train)\n",
    "    y_train_pred = clf_t.predict(X_train)\n",
    "    acc_t = accuracy_score(y_train, y_train_pred)\n",
    "    #clf_v = clf.fit(X_valid, y_valid)\n",
    "    y_valid_pred = clf_t.predict(X_valid)\n",
    "    acc_v = accuracy_score(y_valid, y_valid_pred)\n",
    "    print(acc_t, acc_v, val['best_acc'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Comparando la métrica sobre el train entero, y el de validación, con la que sale de hacer cross validation, se ve que los modelos overfitean cuando se ajustan al entrenamiento (sin cv), y los resultados de accuracy se parecen bastante entre validacion y cv. Es esperable, pero en algunos es muy notable.\n",
    "\n",
    "----\n",
    "\n",
    "* Tomando los resultados de validación los que mejor funcionan son:\n",
    "    \n",
    "    1. `Random forest con (bootstrap=False, class_weight=None, criterion='gini', max_depth=60, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=2, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=780, n_jobs=None, oob_score=False, random_state=42, verbose=0, warm_start=False)`\n",
    "    \n",
    "    2. `RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',max_depth=90, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=100, min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=None, oob_score=False, random_state=42, verbose=0, warm_start=False)`\n",
    "    \n",
    "---\n",
    "\n",
    "* Tomando los resultados de cv, los mejores son también esos dos modelos, pero están cerca las métricas de:\n",
    "\n",
    "    1. `DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=7, min_samples_split=200, min_weight_fraction_leaf=0.0, presort=False, random_state=42, splitter='best')`\n",
    "\n",
    "    2. `DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=12, min_samples_split=200, min_weight_fraction_leaf=0.0, presort=False, random_state=42, splitter='best')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And finally**, we predict the unknown label for the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carla/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/carla/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n",
      "/home/carla/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best sgd accuracy:  0.2729843880791654\n",
      "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
      "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
      "       n_iter_no_change=5, n_jobs=None, penalty='l1', power_t=0.5,\n",
      "       random_state=42, shuffle=True, tol=0.1, validation_fraction=0.1,\n",
      "       verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carla/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:603: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = bb_clf.predict(XX.drop([\"PID\"], axis=1))\n",
    "yy = yy.astype(np.int)\n",
    "submission = pd.DataFrame(list(zip(XX.PID, yy)), columns=[\"PID\", \"AdoptionSpeed\"])\n",
    "submission.to_csv(\"../data/submission.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SGOLKDCikP-Y"
   },
   "source": [
    "The last thing we do is generating a file that should be *submitted* on kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clasificador = {clf:0}\n",
    "\n",
    "yy = results.clf.iloc[0].predict(XX.drop([\"PID\"], axis=1))\n",
    "yy = yy.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(list(zip(XX.PID, yy)), columns=[\"PID\", \"AdoptionSpeed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"../data/submission.csv\", header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "baseline.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
